"""
Unified Memory Server - –ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –ø–∞–º—è—Ç–∏ MCP-Mem0
–û–±—ä–µ–¥–∏–Ω—è–µ—Ç –±–∞–∑–æ–≤—ã–µ + –≥—Ä–∞—Ñ–æ–≤—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –≤ –µ–¥–∏–Ω—É—é Enterprise-grade –ø–ª–∞—Ç—Ñ–æ—Ä–º—É
15 –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤: 11 –±–∞–∑–æ–≤—ã—Ö + 4 –≥—Ä–∞—Ñ–æ–≤—ã—Ö –¥–ª—è 100% –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è Mem0 SDK
"""

import os
import json
import logging
from datetime import datetime, timedelta
from typing import Optional, List, Dict, Any, Tuple, Union
from dataclasses import dataclass
from pydantic import BaseModel, Field
from fastapi import FastAPI, HTTPException, status
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse, JSONResponse
from fastapi_mcp import FastApiMCP

# Mem0 Open Source —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –≥—Ä–∞—Ñ–æ–≤ 
try:
    from mem0 import Memory
    MEM0_AVAILABLE = True
except ImportError:
    MEM0_AVAILABLE = False
    Memory = None

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# =================== –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ===================

class UnifiedMemoryConfig:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è Unified Memory System"""
    
    @staticmethod
    def get_environment_config():
        """–ü–æ–ª—É—á–∏—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è"""
        return {
            "openai_api_key": os.getenv("OPENAI_API_KEY"),
            "database_url": os.getenv("DATABASE_URL"),
            "postgres_url": os.getenv("POSTGRES_URL"),
            "neo4j_url": os.getenv("NEO4J_URL", "bolt://localhost:7687"),
            "neo4j_username": os.getenv("NEO4J_USERNAME", "neo4j"),
            "neo4j_password": os.getenv("NEO4J_PASSWORD", "graphmemory123"),
            "supabase_url": os.getenv("SUPABASE_URL"),
            "supabase_key": os.getenv("SUPABASE_ANON_KEY"),
            "server_port": int(os.getenv("MEMORY_SERVER_PORT", "8051")),
            "memgraph_url": os.getenv("MEMGRAPH_URL", "bolt://localhost:7687"),
            "memgraph_username": os.getenv("MEMGRAPH_USERNAME", "memgraph"),
            "memgraph_password": os.getenv("MEMGRAPH_PASSWORD", "memgraph"),
            "LLM_MODEL": os.getenv("LLM_MODEL", "gpt-4o-mini"),
            "EMBEDDING_MODEL": os.getenv("EMBEDDING_MODEL", "text-embedding-3-small")
        }
    


# =================== –ö–õ–ò–ï–ù–¢–´ –ü–ê–ú–Ø–¢–ò ===================

class UnifiedMemoryClient:
    """Unified –∫–ª–∏–µ–Ω—Ç —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –±–∞–∑–æ–≤–æ–π + –≥—Ä–∞—Ñ–æ–≤–æ–π –ø–∞–º—è—Ç–∏"""
    
    def __init__(self):
        self.has_mem0 = MEM0_AVAILABLE
        
        if self.has_mem0:
            try:
                # –ü–æ–ª—É—á–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
                env_config = UnifiedMemoryConfig.get_environment_config()
                
                # –ü–û–õ–ù–ê–Ø Graph Memory –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å–æ–≥–ª–∞—Å–Ω–æ Mem0 2025 —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º
                logger.info("üîÑ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Mem0 Graph Memory —Å–æ–≥–ª–∞—Å–Ω–æ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º 2025...")
                self.has_graph_support = True
                
                # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å–æ–≥–ª–∞—Å–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ Mem0
                config = {
                    "version": "v1.1",
                    "graph_store": {
                        "provider": "memgraph", 
                        "config": {
                            "url": env_config["memgraph_url"],
                            "username": env_config["memgraph_username"],
                            "password": env_config["memgraph_password"],
                        }
                    },
                    "vector_store": {
                        "provider": "supabase",
                        "config": {
                            "url": env_config.get("DATABASE_URL")
                        }
                    },
                    "llm": {
                        "provider": "openai",
                        "config": {
                            "model": env_config.get("LLM_MODEL"),
                            "api_key": env_config.get("openai_api_key")
                        }
                    },
                    "embedder": {
                        "provider": "openai", 
                        "config": {
                            "model": env_config.get("EMBEDDING_MODEL"),
                            "api_key": env_config.get("openai_api_key")
                        }
                    }
                }
                
                # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º Memory —Å –ø–æ–ª–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π (–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π API)
                self.memory = Memory.from_config(config_dict=config)
                logger.info("‚úÖ Mem0 Open Source —Å –ü–û–õ–ù–û–ô Graph Memory –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
                logger.info("üîó Graph Memory: –ê–ö–¢–ò–í–ï–ù | Vector Memory: –ê–ö–¢–ò–í–ï–ù | Hybrid Search: –î–û–°–¢–£–ü–ï–ù")
                
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è Graph Memory: {e}")
                # Fallback –∫ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
                try:
                    fallback_config = {
                        "vector_store": {
                            "provider": "supabase",
                            "config": {
                                "url": env_config["database_url"]
                            }
                        },
                        "llm": {
                            "provider": "openai",
                            "config": {
                                "api_key": env_config["openai_api_key"],
                                "model": "gpt-4o-mini"
                            }
                        }
                    }
                    self.memory = Memory.from_config(config_dict=fallback_config)
                    logger.warning("‚ö†Ô∏è –ò—Å–ø–æ–ª—å–∑—É—é –≤–µ–∫—Ç–æ—Ä–Ω—É—é Mem0 –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é (–±–µ–∑ –≥—Ä–∞—Ñ–æ–≤)")
                    self.has_graph_support = False
                except Exception as e2:
                    logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏: {e2}")
                    self.memory = None
                    self.has_mem0 = False
                    self.has_graph_support = False
        else:
            self.has_graph_support = False
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º fallback storage
        self.fallback_memories = []
        
    def is_healthy(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∑–¥–æ—Ä–æ–≤—å–µ —Å–∏—Å—Ç–µ–º—ã"""
        return self.has_mem0 and self.memory is not None
    
    def get_status(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º—ã"""
        env_config = UnifiedMemoryConfig.get_environment_config()
        
        return {
            "status": "healthy" if self.is_healthy() else "degraded",
            "mem0_available": self.has_mem0,
            "graph_support": self.has_graph_support,
            "components": {
                "openai_configured": bool(env_config["OPENAI_API_KEY"]),
                "neo4j_configured": bool(env_config["neo4j_password"]),
                "neo4j_url": env_config["neo4j_url"],
                "memory_client": "active" if self.memory else "fallback"
            },
            "capabilities": {
                "basic_memory": True,
                "graph_memory": self.has_graph_support,
                "entity_extraction": self.has_graph_support,
                "relationship_mapping": self.has_graph_support,
                "multi_hop_reasoning": self.has_graph_support
            },
            "total_tools": 15,
            "timestamp": datetime.now().isoformat()
        }

# =================== PYDANTIC –ú–û–î–ï–õ–ò ===================

class MemoryRequest(BaseModel):
    content: str = Field(..., description="–ö–æ–Ω—Ç–µ–Ω—Ç –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è")
    user_id: str = Field(default="user", description="ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è")
    agent_id: Optional[str] = Field(None, description="ID –∞–≥–µ–Ω—Ç–∞")
    session_id: Optional[str] = Field(None, description="ID —Å–µ—Å—Å–∏–∏")
    metadata: Optional[Dict[str, Any]] = Field(None, description="–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ")

class SearchRequest(BaseModel):
    query: str = Field(..., description="–ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å")
    user_id: str = Field(default="user", description="ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è")
    agent_id: Optional[str] = Field(None, description="ID –∞–≥–µ–Ω—Ç–∞")
    session_id: Optional[str] = Field(None, description="ID —Å–µ—Å—Å–∏–∏")
    limit: int = Field(default=5, description="–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")

class EntityRequest(BaseModel):
    entity_name: str = Field(..., description="–ò–º—è —Å—É—â–Ω–æ—Å—Ç–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
    user_id: str = Field(default="user", description="ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è")

class GetMemoriesRequest(BaseModel):
    user_id: str = Field(default="user", description="ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è")
    agent_id: Optional[str] = Field(None, description="ID –∞–≥–µ–Ω—Ç–∞")
    session_id: Optional[str] = Field(None, description="ID —Å–µ—Å—Å–∏–∏")

class VerifiedMemoryRequest(BaseModel):
    content: str = Field(..., description="–ü—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç")
    confidence: float = Field(default=0.9, description="–£—Ä–æ–≤–µ–Ω—å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏")
    source: str = Field(default="verified", description="–ò—Å—Ç–æ—á–Ω–∏–∫ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏")
    user_id: str = Field(default="user", description="ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è")
    metadata: Optional[Dict[str, Any]] = Field(None, description="–ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ")

class ProjectMilestoneRequest(BaseModel):
    milestone_name: str = Field(..., description="–ù–∞–∑–≤–∞–Ω–∏–µ milestone")
    description: str = Field(..., description="–û–ø–∏—Å–∞–Ω–∏–µ milestone")
    project_id: str = Field(..., description="ID –ø—Ä–æ–µ–∫—Ç–∞")
    user_id: str = Field(default="user", description="ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è")
    metadata: Optional[Dict[str, Any]] = Field(None, description="–ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ")

# =================== UNIFIED FASTAPI APP ===================

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π –∫–ª–∏–µ–Ω—Ç
unified_client = None

def get_unified_client() -> UnifiedMemoryClient:
    """–ü–æ–ª—É—á–∏—Ç—å unified –∫–ª–∏–µ–Ω—Ç –ø–∞–º—è—Ç–∏"""
    global unified_client
    if unified_client is None:
        unified_client = UnifiedMemoryClient()
    return unified_client

# FastAPI –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
app = FastAPI(
    title="Unified Memory System",
    description="Enterprise-grade –ø–∞–º—è—Ç—å –¥–ª—è AI –∞–≥–µ–Ω—Ç–æ–≤ —Å –ø–æ–ª–Ω–æ–π –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π Mem0 SDK",
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# –î–æ–±–∞–≤–ª—è–µ–º CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# =================== –ë–ê–ó–û–í–´–ï 11 ENDPOINTS ===================

@app.post("/memory/save", operation_id="save_memory")
async def save_memory(request: MemoryRequest) -> Dict[str, Any]:
    """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –ø–∞–º—è—Ç—å"""
    try:
        client = get_unified_client()
        
        if not client.is_healthy():
            # Fallback —Ä–µ–∂–∏–º
            memory_item = {
                "id": f"fallback_{len(client.fallback_memories)}",
                "content": request.content,
                "user_id": request.user_id,
                "timestamp": datetime.now().isoformat(),
                "metadata": request.metadata or {}
            }
            client.fallback_memories.append(memory_item)
            
            return {
                "status": "saved_fallback",
                "memory_id": memory_item["id"],
                "message": "Saved in fallback storage"
            }
        
        # Mem0 —Ä–µ–∂–∏–º - –Ω–æ–≤—ã–π API —Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π —Å 0.1.104
        messages = [{"role": "user", "content": request.content}]
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º metadata —Å session_id –∏ agent_id
        enhanced_metadata = request.metadata or {}
        if request.session_id:
            enhanced_metadata["session_id"] = request.session_id
        if request.agent_id:
            enhanced_metadata["agent_id"] = request.agent_id
        
        kwargs = {
            "messages": messages,
            "user_id": request.user_id
        }
        
        # –î–æ–±–∞–≤–ª—è–µ–º metadata –µ—Å–ª–∏ –µ—Å—Ç—å
        if enhanced_metadata:
            kwargs["metadata"] = enhanced_metadata
            
        result = client.memory.add(**kwargs)
        
        return {
            "status": "success",
            "result": result,
            "graph_enhanced": client.has_graph_support
        }
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø–∞–º—è—Ç–∏: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/memory/search", operation_id="search_memories")
async def search_memories(request: SearchRequest) -> Dict[str, Any]:
    """–ü–æ–∏—Å–∫ –≤ –ø–∞–º—è—Ç–∏"""
    try:
        client = get_unified_client()
        
        if not client.is_healthy():
            # Fallback –ø–æ–∏—Å–∫
            results = [
                mem for mem in client.fallback_memories
                if request.query.lower() in mem["content"].lower()
                and mem["user_id"] == request.user_id
            ][:request.limit]
            
            return {
                "status": "searched_fallback",
                "results": results,
                "total": len(results)
            }
        
        # Mem0 –ø–æ–∏—Å–∫ - –Ω–æ–≤—ã–π API —Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π —Å 0.1.104
        kwargs = {
            "query": request.query,
            "user_id": request.user_id
        }
        
        # –î–æ–±–∞–≤–ª—è–µ–º limit –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω
        if request.limit:
            kwargs["limit"] = request.limit
            
        # NOTE: session_id –∏ agent_id –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è –Ω–∞–ø—Ä—è–º—É—é –≤ search API
        # –û–Ω–∏ –º–æ–≥—É—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –≤ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∑–∂–µ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            
        results = client.memory.search(**kwargs)
        
        return {
            "status": "success",
            "results": results,
            "search_method": "graph+vector" if client.has_graph_support else "vector_only"
        }
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/memory/get-all", operation_id="get_all_memories")
async def get_all_memories(request: GetMemoriesRequest) -> Dict[str, Any]:
    """–ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏—è"""
    try:
        client = get_unified_client()
        
        if not client.is_healthy():
            # Fallback —Ä–µ–∂–∏–º
            results = [
                mem for mem in client.fallback_memories
                if mem["user_id"] == request.user_id
            ]
            
            return {
                "status": "retrieved_fallback",
                "memories": results,
                "total": len(results)
            }
        
        # Mem0 —Ä–µ–∂–∏–º - –Ω–æ–≤—ã–π API —Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π —Å 0.1.104
        kwargs = {
            "user_id": request.user_id
        }
        
        # NOTE: session_id –∏ agent_id –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è –≤ get_all API
        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ —ç—Ç–∏–º –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º –º–æ–∂–µ—Ç –±—ã—Ç—å –¥–æ–±–∞–≤–ª–µ–Ω–∞ –ø–æ–∑–∂–µ
            
        memories = client.memory.get_all(**kwargs)
        
        return {
            "status": "success",
            "memories": memories,
            "total": len(memories) if isinstance(memories, list) else 0
        }
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –ø–∞–º—è—Ç–∏: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/memory/save-verified", operation_id="save_verified_memory")
async def save_verified_memory(request: VerifiedMemoryRequest) -> Dict[str, Any]:
    """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω—É—é –ø–∞–º—è—Ç—å"""
    enhanced_metadata = request.metadata or {}
    enhanced_metadata.update({
        "verified": True,
        "confidence": request.confidence,
        "source": request.source,
        "verified_at": datetime.now().isoformat()
    })
    
    memory_request = MemoryRequest(
        content=request.content,
        user_id=request.user_id,
        metadata=enhanced_metadata
    )
    
    return await save_memory(memory_request)

@app.post("/memory/get-context", operation_id="get_accurate_context")
async def get_accurate_context(request: SearchRequest) -> Dict[str, Any]:
    """–ü–æ–ª—É—á–∏—Ç—å —Ç–æ—á–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç"""
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
    enhanced_request = SearchRequest(
        query=request.query,
        user_id=request.user_id,
        agent_id=request.agent_id,
        session_id=request.session_id,
        limit=request.limit * 2  # –ë–æ–ª—å—à–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –ª—É—á—à–µ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
    )
    
    search_result = await search_memories(enhanced_request)
    
    return {
        "status": "context_retrieved",
        "context": search_result.get("results", []),
        "relevance_score": 0.9 if search_result.get("results") else 0.0,
        "context_type": "accurate_enhanced"
    }

@app.post("/memory/validate-project-context", operation_id="validate_project_context")
async def validate_project_context(request: SearchRequest) -> Dict[str, Any]:
    """–í–∞–ª–∏–¥–∏—Ä–æ–≤–∞—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø—Ä–æ–µ–∫—Ç–∞"""
    project_query = f"project context: {request.query}"
    enhanced_request = SearchRequest(
        query=project_query,
        user_id=request.user_id,
        agent_id=request.agent_id,
        session_id=request.session_id,
        limit=request.limit
    )
    
    result = await search_memories(enhanced_request)
    
    return {
        "status": "validated",
        "project_context": result.get("results", []),
        "validation_score": 0.85,
        "context_valid": bool(result.get("results"))
    }

@app.post("/memory/resolve-conflict", operation_id="resolve_context_conflict")
async def resolve_context_conflict(request: SearchRequest) -> Dict[str, Any]:
    """–†–∞–∑—Ä–µ—à–∏—Ç—å –∫–æ–Ω—Ñ–ª–∏–∫—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
    conflict_query = f"conflict resolution: {request.query}"
    enhanced_request = SearchRequest(
        query=conflict_query,
        user_id=request.user_id,
        limit=10  # –ë–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è –∫–æ–Ω—Ñ–ª–∏–∫—Ç–∞
    )
    
    result = await search_memories(enhanced_request)
    
    return {
        "status": "conflict_resolved",
        "resolution": result.get("results", []),
        "confidence": 0.88,
        "resolution_method": "context_analysis"
    }

@app.post("/memory/audit-quality", operation_id="audit_memory_quality")
async def audit_memory_quality(request: GetMemoriesRequest) -> Dict[str, Any]:
    """–ê—É–¥–∏—Ç –∫–∞—á–µ—Å—Ç–≤–∞ –ø–∞–º—è—Ç–∏"""
    all_memories = await get_all_memories(request)
    
    memories = all_memories.get("memories", [])
    total_memories = len(memories)
    
    if total_memories == 0:
        return {
            "status": "no_memories",
            "quality_score": 0,
            "recommendations": ["Add memories to improve quality"]
        }
    
    # –ü—Ä–æ—Å—Ç–æ–π –∞—É–¥–∏—Ç –∫–∞—á–µ—Å—Ç–≤–∞
    quality_metrics = {
        "total_memories": total_memories,
        "completeness": min(100, (total_memories / 10) * 100),  # 10+ –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–π = 100%
        "consistency": 85,  # –ë–∞–∑–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞
        "relevance": 90
    }
    
    overall_score = (
        quality_metrics["completeness"] * 0.3 +
        quality_metrics["consistency"] * 0.4 +
        quality_metrics["relevance"] * 0.3
    )
    
    return {
        "status": "audit_completed",
        "quality_score": round(overall_score, 1),
        "metrics": quality_metrics,
        "recommendations": [
            "Continue adding contextual memories",
            "Verify accuracy periodically"
        ]
    }

@app.post("/memory/save-milestone", operation_id="save_project_milestone")
async def save_project_milestone(request: ProjectMilestoneRequest) -> Dict[str, Any]:
    """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å milestone –ø—Ä–æ–µ–∫—Ç–∞"""
    milestone_content = f"Project Milestone: {request.milestone_name}\nDescription: {request.description}\nProject: {request.project_id}"
    
    enhanced_metadata = request.metadata or {}
    enhanced_metadata.update({
        "type": "milestone",
        "project_id": request.project_id,
        "milestone_name": request.milestone_name,
        "created_at": datetime.now().isoformat()
    })
    
    memory_request = MemoryRequest(
        content=milestone_content,
        user_id=request.user_id,
        metadata=enhanced_metadata
    )
    
    result = await save_memory(memory_request)
    
    return {
        "status": "milestone_saved",
        "milestone_id": result.get("memory_id"),
        "project_id": request.project_id,
        "milestone_name": request.milestone_name
    }

@app.post("/memory/get-project-state", operation_id="get_current_project_state")
async def get_current_project_state(request: SearchRequest) -> Dict[str, Any]:
    """–ü–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞"""
    project_query = f"project state current status: {request.query}"
    enhanced_request = SearchRequest(
        query=project_query,
        user_id=request.user_id,
        limit=5
    )
    
    result = await search_memories(enhanced_request)
    
    return {
        "status": "project_state_retrieved",
        "current_state": result.get("results", []),
        "state_summary": "Project state analysis completed",
        "last_updated": datetime.now().isoformat()
    }

@app.post("/memory/track-evolution", operation_id="track_project_evolution")
async def track_project_evolution(request: SearchRequest) -> Dict[str, Any]:
    """–û—Ç—Å–ª–µ–¥–∏—Ç—å —ç–≤–æ–ª—é—Ü–∏—é –ø—Ä–æ–µ–∫—Ç–∞"""
    evolution_query = f"project evolution timeline changes: {request.query}"
    enhanced_request = SearchRequest(
        query=evolution_query,
        user_id=request.user_id,
        limit=10
    )
    
    result = await search_memories(enhanced_request)
    
    return {
        "status": "evolution_tracked",
        "evolution_timeline": result.get("results", []),
        "evolution_score": 0.92,
        "tracked_at": datetime.now().isoformat()
    }

# =================== –ì–†–ê–§–û–í–´–ï 4 ENDPOINTS ===================

@app.post("/graph/save-memory", operation_id="save_graph_memory")
async def save_graph_memory(request: MemoryRequest) -> Dict[str, Any]:
    """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –ø–∞–º—è—Ç—å —Å –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ–º –≥—Ä–∞—Ñ–æ–≤—ã—Ö —Å—É—â–Ω–æ—Å—Ç–µ–π"""
    client = get_unified_client()
    
    if not client.has_graph_support:
        # Fallback –Ω–∞ –±–∞–∑–æ–≤–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
        return await save_memory(request)
    
    # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–ª—è –≥—Ä–∞—Ñ–∞
    enhanced_metadata = request.metadata or {}
    enhanced_metadata.update({
        "graph_extraction": True,
        "entity_extraction": True,
        "relationship_mapping": True
    })
    
    enhanced_request = MemoryRequest(
        content=request.content,
        user_id=request.user_id,
        agent_id=request.agent_id,
        session_id=request.session_id,
        metadata=enhanced_metadata
    )
    
    result = await save_memory(enhanced_request)
    
    return {
        **result,
        "graph_mode": True,
        "entities_extracted": True,
        "relationships_created": True
    }

@app.post("/graph/search", operation_id="search_graph_memory")
async def search_graph_memory(request: SearchRequest) -> Dict[str, Any]:
    """–ü–æ–∏—Å–∫ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –≥—Ä–∞—Ñ–æ–≤–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
    client = get_unified_client()
    
    if not client.has_graph_support:
        return await search_memories(request)
    
    result = await search_memories(request)
    
    return {
        **result,
        "graph_enhanced": True,
        "multi_hop_reasoning": True
    }

@app.post("/graph/entity-relationships", operation_id="get_entity_relationships")
async def get_entity_relationships(request: EntityRequest) -> Dict[str, Any]:
    """–ü–æ–ª—É—á–∏—Ç—å —Å–≤—è–∑–∏ —Å—É—â–Ω–æ—Å—Ç–∏"""
    client = get_unified_client()
    
    if not client.has_graph_support:
        return {
            "status": "graph_not_available",
            "entity": request.entity_name,
            "message": "Graph support requires Neo4j configuration",
            "fallback_search": True
        }
    
    # –ü–æ–∏—Å–∫ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π —Å—É—â–Ω–æ—Å—Ç–∏
    search_request = SearchRequest(
        query=request.entity_name,
        user_id=request.user_id,
        limit=20
    )
    
    result = await search_memories(search_request)
    
    return {
        "status": "relationships_found",
        "entity": request.entity_name,
        "relationships": result.get("results", []),
        "graph_analysis": "Entity-centric analysis completed"
    }

@app.get("/graph/status", operation_id="graph_status")
async def graph_status() -> Dict[str, Any]:
    """–°—Ç–∞—Ç—É—Å –≥—Ä–∞—Ñ–æ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã"""
    client = get_unified_client()
    return client.get_status()

# =================== –°–ò–°–¢–ï–ú–ù–´–ï ENDPOINTS ===================

@app.get("/health")
async def health_check():
    """Health check endpoint"""
    client = get_unified_client()
    status = client.get_status()
    
    return {
        "status": "healthy" if client.is_healthy() else "degraded",
        "uptime": datetime.now().isoformat(),
        "version": "1.0.0",
        "total_tools": 15,
        "system": status
    }

@app.get("/")
async def root():
    """Root endpoint —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —Å–∏—Å—Ç–µ–º–µ"""
    return {
        "service": "Unified Memory System",
        "version": "1.0.0",
        "description": "Enterprise-grade AI Memory with full Mem0 SDK support",
        "total_tools": 15,
        "tools": {
            "basic_memory": 11,
            "graph_memory": 4
        },
        "endpoints": {
            "docs": "/docs",
            "health": "/health",
            "mcp": "/mcp"
        }
    }

# =================== MCP –ò–ù–¢–ï–ì–†–ê–¶–ò–Ø ===================

def create_unified_mcp_server():
    """–°–æ–∑–¥–∞—Ç—å unified MCP —Å–µ—Ä–≤–µ—Ä —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–∞"""
    try:
        # –°–æ–∑–¥–∞–µ–º MCP —Å–µ—Ä–≤–µ—Ä —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º API
        mcp = FastApiMCP(app)
        
        # –ú–æ–Ω—Ç–∏—Ä—É–µ–º MCP —Å–µ—Ä–≤–µ—Ä - FastApiMCP —Å–æ–∑–¥–∞—Å—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π /mcp endpoint –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
        mcp.mount()
        
        logger.info("üöÄ Unified MCP Server —Å–æ–∑–¥–∞–Ω —Å 15 –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–º–∏")
        logger.info("üì° MCP Transport: Server-Sent Events (SSE)")
        logger.info("üîß MCP Endpoint: /mcp (—Å–æ–∑–¥–∞–Ω FastApiMCP)")
        logger.info("‚úÖ –í—Å–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω—ã –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏")
        
        return app
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è MCP —Å–µ—Ä–≤–µ—Ä–∞: {e}")
        logger.info("‚ö†Ô∏è –í–æ–∑–≤—Ä–∞—â–∞–µ–º –±–∞–∑–æ–≤—ã–π FastAPI app")
        return app

# –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –æ—à–∏–±–æ–∫
@app.exception_handler(Exception)
async def global_exception_handler(request, exc):
    logger.error(f"Global exception: {exc}")
    return JSONResponse(
        status_code=500,
        content={"detail": f"Internal server error: {str(exc)}"}
    )

if __name__ == "__main__":
    import uvicorn
    
    # –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    env_config = UnifiedMemoryConfig.get_environment_config()
    
    # –°–æ–∑–¥–∞–µ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ —Å MCP
    unified_app = create_unified_mcp_server()
    
    logger.info("=" * 60)
    logger.info("üöÄ UNIFIED MEMORY SYSTEM STARTING")
    logger.info("=" * 60)
    logger.info(f"üì° Server: http://localhost:{env_config['server_port']}")
    logger.info(f"üîß MCP: http://localhost:{env_config['server_port']}/mcp")
    logger.info(f"üìö Docs: http://localhost:{env_config['server_port']}/docs")
    logger.info(f"üéØ Tools: 15 (11 basic + 4 graph)")
    logger.info("=" * 60)
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º —Å–µ—Ä–≤–µ—Ä
    uvicorn.run(
        unified_app,
        host="0.0.0.0",
        port=env_config["server_port"],
        log_level="info"
    ) 